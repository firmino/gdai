{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"GDAI - Generative Document AI GDAI is a containerized, AI-powered application that leverages a set of specialized services to provide semantic search, secure user authentication, and a scalable API. The application uses Docker Compose for local development and production deployment, ensuring all services work together seamlessly. 1. Getting Started Running the Application To start all services defined in the project, simply run: docker-compose up For running the services in detached mode, use: docker-compose up -d SSL Certificate Generation Before deploying into production, generate SSL certificates for your domains: certbot certonly --standalone -d gdai.site -d www.gdai.site --email firminodefaria@gmail.com --agree-tos --non-interactive --config-dir ./certbot/config --work-dir ./certbot/work --logs-dir ./certbot/logs Make sure ports 80 and 443 are available when running Certbot. 2. Project Structure gdai/ \u251c\u2500\u2500 docker-compose.yml # Docker Compose configuration \u251c\u2500\u2500 .github/ # Github Actions configuration \u2502\u2500\u2500 infra/ # Infrastructure configuration files \u2502\u2500\u2500 src/ # Application \u2502\u2500\u2500 Dockerfile.yml # Dockerfile for project application \u2502\u2500\u2500 pyproject.yml # python project configuration \u2502\u2500\u2500 uv.lock # uv.lock file for project \u2514\u2500\u2500 README.md # Project documentation Note: Additional configuration files (e.g., for Nginx or Certbot) may be provided in external folders or through mounted volumes. 3. Services Infrastructure The services defined in the docker-compose.yml file combine to provide a full-featured environment for GDAI. Below is an explanation of each service: Weaviate Image: semitechnologies/weaviate:latest Purpose: Provides a vector search engine for semantic similarity searches. Configuration: Environment variables set options such as query defaults and anonymous access. Persists data with a named volume ( weaviate_data ). Exposes port 8080 internally and maps it for inter-service communication. Supertokens Image: supertokens/supertokens-postgresql:latest Purpose: Manages secure user authentication and session management. Configuration: Environment variables configure database connection details. It depends on the postgres service to operate. Exposes port 3567 for authentication API calls. Postgres Image: postgres:13-alpine Purpose: Acts as the primary database service supporting both Supertokens and potentially other application data. Configuration: Environment variables define the database, user, and password. Persists data with a named volume ( postgres_data ). FastAPI Application (fastapi-app) Container Name: fastapi-app Purpose: Runs the main API application built with FastAPI. Configuration: Built from the local Dockerfile. Exposes the application on port 8000. Sets environment variables to connect to the Weaviate and Supertokens services. Depends on both weaviate and supertokens to ensure proper startup order. Nginx Image: nginx:alpine Purpose: Acts as a reverse proxy and TLS terminator in a production environment. Configuration: Maps host ports 80 and 443 to the container. Mounts configuration files (from infra/nginx/gdai.conf ) and SSL certificates. Depends on the FastAPI application to start before routing traffic. 4. Configuration Environment Variables (.env) The application uses a .env file for configuration. Below are the main keys you must set: GDAI_LOG_LEVEL=DEBUG GDAI_LOG_FORMAT=[%(asctime)s] [GDAI] [%(levelname)s]: %(message)s GDAI_LOG_FILE_ENABLED=false GDAI_LOG_FILE_PATH=/home/fabricio/projects/g-dai/logs/gdai.log GDAI_LOG_FILE_MAX_SIZE_MB=10 GDAI_LOG_FILE_BACKUP_COUNT=5 RABBIT_MQ_HOST=localhost RABBIT_MQ_PORT=5672 RABBIT_MQ_USER=rabbitmq RABBIT_MQ_PASSWORD=rabbitmq PGVECTOR_USER=testuser PGVECTOR_PASSWORD=testpwd PGVECTOR_DATABASE=vectordb PGVECTOR_HOST=localhost PGVECTOR_PORT=5555 PGVECTOR_MIN_POOL_CONNECTIONS=2 PGVECTOR_MAX_POOL_CONNECTIONS=10 DOCUMENT_EXTRACTOR_FOLDER_SOURCE_PATH=/home/fabricio/projects/g-dai/DOC_FOLDER/raw DOCUMENT_EXTRACTOR_FOLDER_TARGET_PATH=/home/fabricio/projects/g-dai/DOC_FOLDER/extracted DOCUMENT_EXTRACTOR_MAX_FILE_SIZE_MB=100 DOCUMENT_EXTRACTOR=docling DOCUMENT_EXTRACTOR_MAX_RETRIES=3 DOCUMENT_EXTRACTOR_RETRY_DELAY=5 DOCUMENT_EXTRACTOR_QUEUE=extract_data EMBEDDING_FOLDER_SOURCE_PATH=/home/fabricio/projects/g-dai/DOC_FOLDER/extracted EMBEDDING_CHUNK_SIZE=1000 EMBEDDING_CHUNK_OVERLAP=10 EMBEDDING_MAX_RETRIES=3 EMBEDDING_RETRY_DELAY=5 EMBEDDING_QUEUE=embedding_documents EMBEDDING_MAX_MEMORY_USAGE_PERCENT=90 EMBEDDING_MODEL=cohere/embed-v4.0 EMBEDDING_API_KEY=your-cohere-api-key SEARCH_LLM_MODEL=openai/gpt-4o SEARCH_LLM_API_KEY=your-openai-api-key SEARCH_LLM_MAX_TOKENS=1000 SEARCH_LLM_TEMPERATURE=0.7 Note: Replace your-cohere-api-key and your-openai-api-key with your actual API keys. 5. Deployment & Running Local Development Install Docker and Docker Compose (if not already installed). Clone the repository and copy .env.example to .env , then fill in the required values. Start all services: bash docker-compose up --build Or in detached mode: bash docker-compose up -d Access the API: By default, the FastAPI app will be available at http://localhost:8000 . Production Configure Nginx and SSL as described above. Ensure all environment variables are set securely. Use a process manager (e.g., systemd, Docker Compose in production mode). 6. API Usage Search Query Endpoint POST /search/query Request Body: json { \"tenant_id\": \"string\", \"query_id\": \"string\", \"query_text\": \"string\", \"chunks_limit\": 100 } Response: json { \"message\": \"string\", \"query_id\": \"string\", \"status\": \"success\", \"list_chunks\": [ ... ] } Document Upload Endpoint POST /search/document/upload Form Data: tenant_id : string document : file (PDF, etc) Response: json { \"message\": \"Document <filename> uploaded and queued for processing\", \"document_name\": \"<filename>\", \"tenant_id\": \"<tenant_id>\", \"status\": \"pending\" } 7. How to Use Upload a document via /search/document/upload (multipart form-data). Submit a search query via /search/query (JSON body). Results will be based on the processed documents for the given tenant. 8. Troubleshooting Check logs for errors: docker-compose logs or check the log file if enabled. Ensure all environment variables are set and valid. For database or broker issues, verify service health and credentials. 9. Contributing Fork the repository, create a feature branch, and submit a pull request. Please document new endpoints and configuration options. 10. License See LICENSE for details. Happy coding!","title":"Home"},{"location":"#gdai-generative-document-ai","text":"GDAI is a containerized, AI-powered application that leverages a set of specialized services to provide semantic search, secure user authentication, and a scalable API. The application uses Docker Compose for local development and production deployment, ensuring all services work together seamlessly.","title":"GDAI - Generative Document AI"},{"location":"#1-getting-started","text":"","title":"1. Getting Started"},{"location":"#running-the-application","text":"To start all services defined in the project, simply run: docker-compose up For running the services in detached mode, use: docker-compose up -d","title":"Running the Application"},{"location":"#ssl-certificate-generation","text":"Before deploying into production, generate SSL certificates for your domains: certbot certonly --standalone -d gdai.site -d www.gdai.site --email firminodefaria@gmail.com --agree-tos --non-interactive --config-dir ./certbot/config --work-dir ./certbot/work --logs-dir ./certbot/logs Make sure ports 80 and 443 are available when running Certbot.","title":"SSL Certificate Generation"},{"location":"#2-project-structure","text":"gdai/ \u251c\u2500\u2500 docker-compose.yml # Docker Compose configuration \u251c\u2500\u2500 .github/ # Github Actions configuration \u2502\u2500\u2500 infra/ # Infrastructure configuration files \u2502\u2500\u2500 src/ # Application \u2502\u2500\u2500 Dockerfile.yml # Dockerfile for project application \u2502\u2500\u2500 pyproject.yml # python project configuration \u2502\u2500\u2500 uv.lock # uv.lock file for project \u2514\u2500\u2500 README.md # Project documentation Note: Additional configuration files (e.g., for Nginx or Certbot) may be provided in external folders or through mounted volumes.","title":"2. Project Structure"},{"location":"#3-services-infrastructure","text":"The services defined in the docker-compose.yml file combine to provide a full-featured environment for GDAI. Below is an explanation of each service:","title":"3. Services Infrastructure"},{"location":"#weaviate","text":"Image: semitechnologies/weaviate:latest Purpose: Provides a vector search engine for semantic similarity searches. Configuration: Environment variables set options such as query defaults and anonymous access. Persists data with a named volume ( weaviate_data ). Exposes port 8080 internally and maps it for inter-service communication.","title":"Weaviate"},{"location":"#supertokens","text":"Image: supertokens/supertokens-postgresql:latest Purpose: Manages secure user authentication and session management. Configuration: Environment variables configure database connection details. It depends on the postgres service to operate. Exposes port 3567 for authentication API calls.","title":"Supertokens"},{"location":"#postgres","text":"Image: postgres:13-alpine Purpose: Acts as the primary database service supporting both Supertokens and potentially other application data. Configuration: Environment variables define the database, user, and password. Persists data with a named volume ( postgres_data ).","title":"Postgres"},{"location":"#fastapi-application-fastapi-app","text":"Container Name: fastapi-app Purpose: Runs the main API application built with FastAPI. Configuration: Built from the local Dockerfile. Exposes the application on port 8000. Sets environment variables to connect to the Weaviate and Supertokens services. Depends on both weaviate and supertokens to ensure proper startup order.","title":"FastAPI Application (fastapi-app)"},{"location":"#nginx","text":"Image: nginx:alpine Purpose: Acts as a reverse proxy and TLS terminator in a production environment. Configuration: Maps host ports 80 and 443 to the container. Mounts configuration files (from infra/nginx/gdai.conf ) and SSL certificates. Depends on the FastAPI application to start before routing traffic.","title":"Nginx"},{"location":"#4-configuration","text":"","title":"4. Configuration"},{"location":"#environment-variables-env","text":"The application uses a .env file for configuration. Below are the main keys you must set: GDAI_LOG_LEVEL=DEBUG GDAI_LOG_FORMAT=[%(asctime)s] [GDAI] [%(levelname)s]: %(message)s GDAI_LOG_FILE_ENABLED=false GDAI_LOG_FILE_PATH=/home/fabricio/projects/g-dai/logs/gdai.log GDAI_LOG_FILE_MAX_SIZE_MB=10 GDAI_LOG_FILE_BACKUP_COUNT=5 RABBIT_MQ_HOST=localhost RABBIT_MQ_PORT=5672 RABBIT_MQ_USER=rabbitmq RABBIT_MQ_PASSWORD=rabbitmq PGVECTOR_USER=testuser PGVECTOR_PASSWORD=testpwd PGVECTOR_DATABASE=vectordb PGVECTOR_HOST=localhost PGVECTOR_PORT=5555 PGVECTOR_MIN_POOL_CONNECTIONS=2 PGVECTOR_MAX_POOL_CONNECTIONS=10 DOCUMENT_EXTRACTOR_FOLDER_SOURCE_PATH=/home/fabricio/projects/g-dai/DOC_FOLDER/raw DOCUMENT_EXTRACTOR_FOLDER_TARGET_PATH=/home/fabricio/projects/g-dai/DOC_FOLDER/extracted DOCUMENT_EXTRACTOR_MAX_FILE_SIZE_MB=100 DOCUMENT_EXTRACTOR=docling DOCUMENT_EXTRACTOR_MAX_RETRIES=3 DOCUMENT_EXTRACTOR_RETRY_DELAY=5 DOCUMENT_EXTRACTOR_QUEUE=extract_data EMBEDDING_FOLDER_SOURCE_PATH=/home/fabricio/projects/g-dai/DOC_FOLDER/extracted EMBEDDING_CHUNK_SIZE=1000 EMBEDDING_CHUNK_OVERLAP=10 EMBEDDING_MAX_RETRIES=3 EMBEDDING_RETRY_DELAY=5 EMBEDDING_QUEUE=embedding_documents EMBEDDING_MAX_MEMORY_USAGE_PERCENT=90 EMBEDDING_MODEL=cohere/embed-v4.0 EMBEDDING_API_KEY=your-cohere-api-key SEARCH_LLM_MODEL=openai/gpt-4o SEARCH_LLM_API_KEY=your-openai-api-key SEARCH_LLM_MAX_TOKENS=1000 SEARCH_LLM_TEMPERATURE=0.7 Note: Replace your-cohere-api-key and your-openai-api-key with your actual API keys.","title":"Environment Variables (.env)"},{"location":"#5-deployment-running","text":"","title":"5. Deployment &amp; Running"},{"location":"#local-development","text":"Install Docker and Docker Compose (if not already installed). Clone the repository and copy .env.example to .env , then fill in the required values. Start all services: bash docker-compose up --build Or in detached mode: bash docker-compose up -d Access the API: By default, the FastAPI app will be available at http://localhost:8000 .","title":"Local Development"},{"location":"#production","text":"Configure Nginx and SSL as described above. Ensure all environment variables are set securely. Use a process manager (e.g., systemd, Docker Compose in production mode).","title":"Production"},{"location":"#6-api-usage","text":"","title":"6. API Usage"},{"location":"#search-query-endpoint","text":"POST /search/query Request Body: json { \"tenant_id\": \"string\", \"query_id\": \"string\", \"query_text\": \"string\", \"chunks_limit\": 100 } Response: json { \"message\": \"string\", \"query_id\": \"string\", \"status\": \"success\", \"list_chunks\": [ ... ] }","title":"Search Query Endpoint"},{"location":"#document-upload-endpoint","text":"POST /search/document/upload Form Data: tenant_id : string document : file (PDF, etc) Response: json { \"message\": \"Document <filename> uploaded and queued for processing\", \"document_name\": \"<filename>\", \"tenant_id\": \"<tenant_id>\", \"status\": \"pending\" }","title":"Document Upload Endpoint"},{"location":"#7-how-to-use","text":"Upload a document via /search/document/upload (multipart form-data). Submit a search query via /search/query (JSON body). Results will be based on the processed documents for the given tenant.","title":"7. How to Use"},{"location":"#8-troubleshooting","text":"Check logs for errors: docker-compose logs or check the log file if enabled. Ensure all environment variables are set and valid. For database or broker issues, verify service health and credentials.","title":"8. Troubleshooting"},{"location":"#9-contributing","text":"Fork the repository, create a feature branch, and submit a pull request. Please document new endpoints and configuration options.","title":"9. Contributing"},{"location":"#10-license","text":"See LICENSE for details. Happy coding!","title":"10. License"},{"location":"about/","text":"about","title":"About"},{"location":"code_of_conduct/","text":"","title":"Code of Conduct"},{"location":"contributing/","text":"","title":"Contributing"}]}